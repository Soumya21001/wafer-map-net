{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import models\n",
    "from torchvision.transforms import functional as TF\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for Dataset 1 (WM811K)\n",
    "def preprocess_wm811k_data(path_to_dataset, target_size=(32, 32), num_classes=8, multi_label_ratio=1.0):\n",
    "    \"\"\"\n",
    "    Load and preprocess the WM811K dataset and generate synthetic multi-label data.\n",
    "\n",
    "    Parameters:\n",
    "        path_to_dataset (str): Path to the WM811K .pkl dataset.\n",
    "        target_size (tuple): Desired image size.\n",
    "        num_classes (int): Total number of classes.\n",
    "        multi_label_ratio (float): Fraction of multi-label samples to generate.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Preprocessed wafer maps.\n",
    "        np.ndarray: Multi-label one-hot encoded labels.\n",
    "    \"\"\"\n",
    "    df = pd.read_pickle(path_to_dataset)\n",
    "    df = df.drop(['waferIndex'], axis=1)\n",
    "    df['failureNum'] = df['failureType']\n",
    "\n",
    "    mapping_type = {\n",
    "        'Center': 0, 'Donut': 1, 'Edge-Loc': 2, 'Edge-Ring': 3,\n",
    "        'Loc': 4, 'Random': 5, 'Scratch': 6, 'Near-full': 7, 'none': -1}\n",
    "    df = df.replace({'failureNum': mapping_type})\n",
    "    df = df[(df['failureNum'] >= 0)].reset_index()\n",
    "\n",
    "    # Filter out invalid data\n",
    "    valid_indices = df[\"failureNum\"].apply(\n",
    "        lambda x: x is not None and isinstance(x, (int, np.integer)))\n",
    "    df = df[valid_indices]\n",
    "\n",
    "    wafer_maps = df['waferMap'].to_numpy()\n",
    "    labels = df['failureNum'].to_numpy()\n",
    "\n",
    "    processed_maps = []\n",
    "    for wafer_map in wafer_maps:\n",
    "        if wafer_map.size == 0:  # Skip invalid or empty maps\n",
    "            continue\n",
    "        wafer_map = np.array(wafer_map, dtype=np.float32)\n",
    "        wafer_map = (wafer_map - np.min(wafer_map)) / \\\n",
    "            (np.max(wafer_map) - np.min(wafer_map))\n",
    "        scaling_factor = min(\n",
    "            target_size[1] / wafer_map.shape[1], target_size[0] / wafer_map.shape[0])\n",
    "        new_width = int(wafer_map.shape[1] * scaling_factor)\n",
    "        new_height = int(wafer_map.shape[0] * scaling_factor)\n",
    "        resized_map = cv2.resize(\n",
    "            wafer_map, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "        padded_map = np.full(target_size, 0, dtype=np.float32)\n",
    "        x_offset = (target_size[1] - new_width) // 2\n",
    "        y_offset = (target_size[0] - new_height) // 2\n",
    "        padded_map[y_offset:y_offset + new_height,\n",
    "                   x_offset:x_offset + new_width] = resized_map\n",
    "        processed_maps.append(padded_map)\n",
    "\n",
    "    # One-hot encode labels\n",
    "    encoder = OneHotEncoder(sparse_output=False, categories='auto')\n",
    "    labels = labels.reshape(-1, 1)  # Reshape for one-hot encoding\n",
    "\n",
    "    # Separate 'none' and encode others\n",
    "    is_none = labels == -1\n",
    "    one_hot_labels = encoder.fit_transform(labels[~is_none].reshape(-1, 1))\n",
    "    final_labels = np.zeros((len(labels), num_classes), dtype=np.float32)\n",
    "    final_labels[~is_none.flatten()] = one_hot_labels\n",
    "\n",
    "    # Generate synthetic multi-label samples directly without oversampling\n",
    "    num_samples = len(processed_maps)\n",
    "    print(num_samples)\n",
    "    num_multi_class_samples = int(multi_label_ratio * num_samples)\n",
    "    multi_class_maps = []\n",
    "    multi_class_labels = []\n",
    "\n",
    "    for _ in range(num_multi_class_samples):\n",
    "        # Randomly select two or more samples to combine\n",
    "        indices = np.random.choice(len(processed_maps), size=2, replace=False)\n",
    "\n",
    "        # Combine maps with consistent dimensions\n",
    "        combined_map = np.maximum(\n",
    "            processed_maps[indices[0]], processed_maps[indices[1]])\n",
    "        combined_label = np.logical_or(\n",
    "            final_labels[indices[0]], final_labels[indices[1]]).astype(np.float32)\n",
    "\n",
    "        # Ensure padding for consistency\n",
    "        resized_combined_map = cv2.resize(\n",
    "            combined_map, target_size, interpolation=cv2.INTER_AREA)\n",
    "        multi_class_maps.append(resized_combined_map)\n",
    "        multi_class_labels.append(combined_label)\n",
    "\n",
    "    # Combine original and synthetic data\n",
    "    all_maps = np.vstack(\n",
    "        [np.array(processed_maps), np.array(multi_class_maps)])\n",
    "    all_labels = np.vstack([final_labels, np.array(multi_class_labels)])\n",
    "\n",
    "    return np.expand_dims(all_maps, axis=1), all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for Dataset 2 (MixedWM38)\n",
    "def preprocess_npz_dataset(path, target_size=(32, 32), num_classes=8):\n",
    "    \"\"\"\n",
    "    Preprocess the .npz dataset for mixed-type wafer maps.\n",
    "\n",
    "    Parameters:\n",
    "        path (str): Path to the .npz dataset.\n",
    "        target_size (tuple): Desired image size.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Preprocessed wafer maps.\n",
    "        np.ndarray: Multi-label one-hot encoded labels.\n",
    "    \"\"\"\n",
    "    data = np.load(path)\n",
    "    wafer_maps = data['arr_0']\n",
    "    multi_labels = data['arr_1']\n",
    "\n",
    "    # Exclude samples where all labels are zero (indicating 'none')\n",
    "    valid_indices = np.any(multi_labels, axis=1)\n",
    "    wafer_maps = wafer_maps[valid_indices]\n",
    "    multi_labels = multi_labels[valid_indices]\n",
    "\n",
    "    processed_maps = []\n",
    "    for wafer_map in wafer_maps:\n",
    "        wafer_map = np.array(wafer_map, dtype=np.float32)\n",
    "        wafer_map = (wafer_map - np.min(wafer_map)) / \\\n",
    "            (np.max(wafer_map) - np.min(wafer_map))\n",
    "        resized_map = cv2.resize(\n",
    "            wafer_map, target_size, interpolation=cv2.INTER_AREA)\n",
    "        processed_maps.append(resized_map)\n",
    "\n",
    "    # One-hot encode multi-labels, excluding 'none'\n",
    "    multi_label_one_hot = np.zeros(\n",
    "        (len(multi_labels), num_classes), dtype=np.float32)\n",
    "    for i, label in enumerate(multi_labels):\n",
    "        for defect in label.nonzero()[0]:\n",
    "            if defect < num_classes:  # Exclude \"none\" from encoding\n",
    "                multi_label_one_hot[i, defect] = 1\n",
    "\n",
    "    return np.expand_dims(np.array(processed_maps), axis=1), multi_label_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, train_labels = preprocess_wm811k_data(\n",
    "#     \"data/WM811K.pkl\", target_size=(32, 32), num_classes=8, multi_label_ratio=1.0)\n",
    "# test_data, test_labels = preprocess_npz_dataset(\n",
    "#     \"data/MLWM38K.npz\", target_size=(32, 32), num_classes=8)\n",
    "\n",
    "# # Save train data and labels\n",
    "# np.savez_compressed(\"data/preprocessed_train_data.npz\",\n",
    "#                     data=train_data, labels=train_labels)\n",
    "\n",
    "# # Save test data and labels\n",
    "# np.savez_compressed(\"data/preprocessed_test_data.npz\",\n",
    "#                     data=test_data, labels=test_labels)\n",
    "\n",
    "# print(\"Preprocessed data saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preprocessed data loaded successfully!\")\n",
    "# Load train data and labels\n",
    "train_data = np.load(\"data/preprocessed_train_data.npz\")['data']\n",
    "train_labels = np.load(\"data/preprocessed_train_data.npz\")['labels']\n",
    "print(\n",
    "    f\"Train Data Shape: {train_data.shape}, Train Labels Shape: {train_labels.shape}\")\n",
    "\n",
    "# Load test data and labels\n",
    "test_data = np.load(\"data/preprocessed_test_data.npz\")['data']\n",
    "test_labels = np.load(\"data/preprocessed_test_data.npz\")['labels']\n",
    "print(\n",
    "    f\"Test Data Shape: {test_data.shape}, Test Labels Shape: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize random samples from the dataset\n",
    "def visualize_samples(data, labels, num_samples=5, dataset_name=\"Dataset\"):\n",
    "    \"\"\"\n",
    "    Visualizes random samples from the dataset with their labels.\n",
    "\n",
    "    Parameters:\n",
    "        data (np.ndarray): Wafer map data (preprocessed).\n",
    "        labels (np.ndarray): Corresponding labels (one-hot encoded).\n",
    "        num_samples (int): Number of samples to visualize.\n",
    "        dataset_name (str): Name of the dataset for title purposes.\n",
    "    \"\"\"\n",
    "    num_classes = labels.shape[1]\n",
    "    indices = np.random.choice(len(data), size=num_samples, replace=False)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        wafer_map = data[idx].squeeze()  # Remove channel dimension\n",
    "        label = labels[idx]\n",
    "\n",
    "        plt.subplot(1, num_samples, i + 1)\n",
    "        plt.imshow(wafer_map, cmap='gray')\n",
    "        label_text = ', '.join(\n",
    "            [f\"Class {j}\" for j in range(num_classes) if label[j] == 1])\n",
    "        plt.title(f\"Sample {idx}\\n{label_text if label_text else 'None'}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.suptitle(f\"Random Samples from {dataset_name}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Dataset 1\n",
    "visualize_samples(train_data, train_labels, num_samples=8,\n",
    "                  dataset_name=\"Dataset 1 (Single Label)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Dataset 2\n",
    "visualize_samples(test_data, test_labels, num_samples=8,\n",
    "                  dataset_name=\"Dataset 2 (Multi-Label)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum along the first axis (rows) to get the count of samples for each class\n",
    "class_counts = train_labels.sum(axis=0)\n",
    "\n",
    "# Normalize to get the proportion of each class\n",
    "class_proportions = class_counts / train_labels.shape[0]\n",
    "\n",
    "print(\"Class Counts:\", class_counts)\n",
    "print(\"Class Proportions:\", class_proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum along the first axis (rows) to count occurrences of each class across all samples\n",
    "class_counts = test_labels.sum(axis=0)\n",
    "\n",
    "# Normalize to get proportions\n",
    "class_proportions = class_counts / test_labels.shape[0]\n",
    "\n",
    "print(\"Class Counts:\", class_counts)\n",
    "print(\"Class Proportions:\", class_proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset for PyTorch\n",
    "class WaferDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.tensor(self.data[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16Classifier(nn.Module):\n",
    "    def __init__(self, init_weights=True, num_classes=8, feature_dim=512):\n",
    "        \"\"\"\n",
    "        VGG16-based Classifier for multi-label classification.\n",
    "\n",
    "        Parameters:\n",
    "            init_weights (bool): Whether to initialize weights.\n",
    "            num_class (int): Number of output classes.\n",
    "            feature_dim (int): Feature dimensionality from the feature extractor.\n",
    "        \"\"\"\n",
    "        super(VGG16Classifier, self).__init__()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Linear(feature_dim * 7 * 7, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten features for linear layers\n",
    "        x = self.classifier(x)\n",
    "        return x  # torch.sigmoid(x)  # Sigmoid for multi-label classification\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"\n",
    "        Initializes the weights of the classifier layers.\n",
    "        \"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training(data, labels, batch_size, subset_size):\n",
    "    def apply_transform(image):\n",
    "        \"\"\"\n",
    "        Manually apply transformations to a grayscale numpy.ndarray image.\n",
    "        \"\"\"\n",
    "        # Ensure input is of shape (H, W) for processing\n",
    "        # Remove the single channel dimension (1, H, W) -> (H, W)\n",
    "        image = image.squeeze(0)\n",
    "\n",
    "        # Resize to 256x256\n",
    "        image = TF.resize(torch.tensor(image).unsqueeze(0),\n",
    "                          size=(256, 256)).squeeze(0).numpy()\n",
    "\n",
    "        # Random horizontal flip (50% chance)\n",
    "        if np.random.rand() > 0.5:\n",
    "            image = np.fliplr(image)\n",
    "\n",
    "        # Center crop to 224x224\n",
    "        h, w = image.shape[-2:]\n",
    "        top = (h - 224) // 2\n",
    "        left = (w - 224) // 2\n",
    "        image = image[top:top + 224, left:left + 224]\n",
    "\n",
    "        # Normalize using mean and std for grayscale\n",
    "        image = (image - 0.5) / 0.5  # Normalize grayscale to range [-1, 1]\n",
    "\n",
    "        # Restore to (1, H, W) format\n",
    "        return image[np.newaxis, :, :]  # Add the channel dimension back\n",
    "\n",
    "    # Subset the data if subset_size is provided\n",
    "    if subset_size is not None:\n",
    "        indices = np.random.choice(len(data), subset_size, replace=False)\n",
    "        data = data[indices]\n",
    "        labels = labels[indices]\n",
    "\n",
    "    # Apply the transformation to all images\n",
    "    transformed_data = [apply_transform(image) for image in data]\n",
    "\n",
    "    # Create the WaferDataset with transformed data\n",
    "    train_dataset = WaferDataset(data=transformed_data, labels=labels)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_testing(data, labels, batch_size, subset_size):\n",
    "    def apply_transform(image):\n",
    "        \"\"\"\n",
    "        Manually apply transformations to a grayscale numpy.ndarray image.\n",
    "        \"\"\"\n",
    "        # Ensure input is of shape (H, W) for processing\n",
    "        # Remove the single channel dimension (1, H, W) -> (H, W)\n",
    "        image = image.squeeze(0)\n",
    "\n",
    "        # Resize to 256x256\n",
    "        image = TF.resize(torch.tensor(image).unsqueeze(0),\n",
    "                          size=(256, 256)).squeeze(0).numpy()\n",
    "\n",
    "        # Random horizontal flip (50% chance)\n",
    "        if np.random.rand() > 0.5:\n",
    "            image = np.fliplr(image)\n",
    "\n",
    "        # Center crop to 224x224\n",
    "        h, w = image.shape[-2:]\n",
    "        top = (h - 224) // 2\n",
    "        left = (w - 224) // 2\n",
    "        image = image[top:top + 224, left:left + 224]\n",
    "\n",
    "        # Normalize using mean and std for grayscale\n",
    "        image = (image - 0.5) / 0.5  # Normalize grayscale to range [-1, 1]\n",
    "\n",
    "        # Restore to (1, H, W) format\n",
    "        return image[np.newaxis, :, :]  # Add the channel dimension back\n",
    "\n",
    "    # Subset the data if subset_size is provided\n",
    "    if subset_size is not None:\n",
    "        indices = np.random.choice(len(data), subset_size, replace=False)\n",
    "        data = data[indices]\n",
    "        labels = labels[indices]\n",
    "    # Apply the transformation to all images\n",
    "    transformed_data = [apply_transform(image) for image in data]\n",
    "\n",
    "    test_dataset = WaferDataset(data=transformed_data, labels=labels)\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0, verbose=False):\n",
    "        \"\"\"\n",
    "        Early stops the training if validation loss doesn't improve after a given patience.\n",
    "\n",
    "        Parameters:\n",
    "            patience (int): Number of epochs to wait before stopping.\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "            verbose (bool): Whether to print messages when stopping.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(\n",
    "                    f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDADA:\n",
    "    def __init__(self, train_data, train_labels, test_data, test_labels, num_classes=8, max_epoch=50, batch_size=32, learning_rate=0.0005, subset_size=None):\n",
    "        \"\"\"\n",
    "        Initializes the CDADA training and evaluation pipeline.\n",
    "\n",
    "        Parameters:\n",
    "            train_data (np.ndarray): Training data.\n",
    "            train_labels (np.ndarray): Labels for the training data.\n",
    "            test_data (np.ndarray): Testing data.\n",
    "            test_labels (np.ndarray): Labels for the testing data.\n",
    "            num_classes (int): Number of classes for multi-label classification.\n",
    "            max_epoch (int): Maximum number of epochs.\n",
    "            batch_size (int): Batch size for training and testing.\n",
    "            learning_rate (float): Learning rate for optimizers.\n",
    "        \"\"\"\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.max_epoch = max_epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.train_loader = load_training(\n",
    "            train_data, train_labels, batch_size=batch_size, subset_size=subset_size)\n",
    "        print(\n",
    "            f\"Size of the training dataset: {len(self.train_loader.dataset)}\")\n",
    "        self.test_loader = load_testing(\n",
    "            test_data, test_labels, batch_size=batch_size, subset_size=subset_size)\n",
    "        self.updata = 6\n",
    "        self.t_correct = 0\n",
    "\n",
    "        # Initialize VGG16 model\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        # Modify for grayscale input\n",
    "        model.features[0] = nn.Conv2d(\n",
    "            1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.feature_extractor = model.features.to(device)\n",
    "        self.classifier = VGG16Classifier(num_classes=num_classes).to(device)\n",
    "        self.classifier1 = VGG16Classifier(num_classes=num_classes).to(device)\n",
    "        self.classifier2 = VGG16Classifier(num_classes=num_classes).to(device)\n",
    "\n",
    "        # optimizer and loss\n",
    "        self.opt_generator = optim.Adam(list(self.feature_extractor.parameters(\n",
    "        )) + list(self.classifier.parameters()), lr=learning_rate, weight_decay=0.0005)  # weight_decay=1e-4\n",
    "        self.opt_classifier = optim.Adam(\n",
    "            self.classifier.parameters(), lr=learning_rate, weight_decay=0.0005)\n",
    "        self.opt_classifier1 = optim.Adam(\n",
    "            self.classifier.parameters(), lr=learning_rate, weight_decay=0.0005)\n",
    "        self.opt_classifier2 = optim.Adam(\n",
    "            self.classifier.parameters(), lr=learning_rate, weight_decay=0.0005)\n",
    "\n",
    "        # Compute class weights\n",
    "        # Sum occurrences for each class\n",
    "        class_counts = train_labels.sum(axis=0)\n",
    "        total_samples = len(train_labels)\n",
    "        class_weights = total_samples / (num_classes * class_counts)\n",
    "        self.class_weights = torch.tensor(\n",
    "            class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "        # Track losses\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def reset_grad(self):\n",
    "        self.opt_generator.zero_grad()\n",
    "        self.opt_classifier.zero_grad()\n",
    "        self.opt_classifier1.zero_grad()\n",
    "        self.opt_classifier2.zero_grad()\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Trains the model with the weighted loss function.\n",
    "        \"\"\"\n",
    "        print(\n",
    "            f\"Size of the training dataset: {len(self.train_loader.dataset)}\")\n",
    "        self.feature_extractor.train()\n",
    "        self.classifier.train()\n",
    "        self.classifier1.train()\n",
    "        self.classifier2.train()\n",
    "        torch.cuda.manual_seed(1)\n",
    "\n",
    "        # Initialize early stopping\n",
    "        early_stopping = EarlyStopping(patience=5, delta=0.01, verbose=True)\n",
    "\n",
    "        for ep in range(self.max_epoch):\n",
    "            time_start = time.time()\n",
    "            running_loss = 0\n",
    "\n",
    "            print(f\"No.of loops: {len(self.train_loader)}\")\n",
    "            for images, labels in self.train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                self.reset_grad()\n",
    "\n",
    "                # Forward pass for source domain\n",
    "                features = self.feature_extractor(images)\n",
    "                pred_outputs_c = self.classifier(features)\n",
    "                pred_outputs_c1 = self.classifier1(features)\n",
    "                pred_outputs_c2 = self.classifier2(features)\n",
    "\n",
    "                # Compute source domain loss\n",
    "                loss_c = self.criterion(pred_outputs_c, labels)\n",
    "                loss_c1 = self.criterion(pred_outputs_c1, labels)\n",
    "                loss_c2 = self.criterion(pred_outputs_c2, labels)\n",
    "                loss = loss_c + loss_c1 + loss_c2\n",
    "                loss.backward()\n",
    "\n",
    "                # Apply gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(self.feature_extractor.parameters(), max_norm=1.0)\n",
    "                torch.nn.utils.clip_grad_norm_(self.classifier.parameters(), max_norm=1.0)\n",
    "\n",
    "                # Update parameters\n",
    "                self.opt_generator.step()\n",
    "                self.opt_classifier.step()\n",
    "                self.opt_classifier1.step()\n",
    "                self.opt_classifier2.step()\n",
    "\n",
    "                self.reset_grad()\n",
    "\n",
    "                # Adversarial loss computation\n",
    "                features = self.feature_extractor(images)\n",
    "                pred_outputs_c1 = self.classifier1(features)\n",
    "                pred_outputs_c2 = self.classifier2(features)\n",
    "                loss_c1 = self.criterion(pred_outputs_c1, labels)\n",
    "                loss_c2 = self.criterion(pred_outputs_c2, labels)\n",
    "                loss = loss_c1 + loss_c2\n",
    "\n",
    "                # Adversarial loss computation\n",
    "                # Using the same loader for simplicity\n",
    "                features_tgt = self.feature_extractor(images)\n",
    "                pred_tgt_c1 = self.classifier1(features_tgt)\n",
    "                pred_tgt_c2 = self.classifier2(features_tgt)\n",
    "                p1 = F.softmax(pred_tgt_c1, dim=1)\n",
    "                p2 = F.softmax(pred_tgt_c2, dim=1)\n",
    "                loss_adv = torch.mean(torch.abs(p1 - p2))\n",
    "                loss = loss - loss_adv\n",
    "                loss.backward()\n",
    "\n",
    "                self.opt_classifier1.step()\n",
    "                self.opt_classifier2.step()\n",
    "\n",
    "                self.reset_grad()\n",
    "\n",
    "                # Adversarial generator update\n",
    "                for _ in range(self.updata):\n",
    "                    features_tgt = self.feature_extractor(images)\n",
    "                    pred_tgt_c1 = self.classifier1(features_tgt)\n",
    "                    pred_tgt_c2 = self.classifier2(features_tgt)\n",
    "                    p1 = F.softmax(pred_tgt_c1, dim=1)\n",
    "                    p2 = F.softmax(pred_tgt_c2, dim=1)\n",
    "                    loss_adv = torch.mean(torch.abs(p1 - p2))\n",
    "\n",
    "                    loss_adv.backward()\n",
    "                    self.opt_generator.step()\n",
    "                    self.reset_grad()\n",
    "\n",
    "                running_loss += loss_adv.item()\n",
    "\n",
    "            time_end = time.time()\n",
    "            time_delta = time_end - time_start\n",
    "\n",
    "            # Log epoch details\n",
    "            print(\n",
    "                f'Epoch {ep + 1}, Adversarial Loss: {loss_adv.item():.6f}, Time: {time_delta}')\n",
    "\n",
    "            # Save loss to a file\n",
    "            output_path = f'data/Trainresultsloss.txt'\n",
    "            with open(output_path, 'a') as output:\n",
    "                output.write(f'{loss_adv.item()}\\n')\n",
    "\n",
    "            # Test target domain accuracy\n",
    "            target_accuracy = self.test()\n",
    "\n",
    "            # Check for early stopping\n",
    "            early_stopping(target_accuracy)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping triggered. Training stopped.\")\n",
    "                break\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        Tests the model and computes accuracy, precision, recall, and F1 score..\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        print(\"Testing\")\n",
    "        self.feature_extractor.eval()\n",
    "        self.classifier.eval()\n",
    "\n",
    "        correct = 0\n",
    "        size = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in self.test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                features = self.feature_extractor(images)\n",
    "                pred = self.classifier(features)\n",
    "\n",
    "                # Get predicted labels\n",
    "                pred = pred.max(1)[1]\n",
    "                label_indices = labels.max(1)[1]\n",
    "                k = labels.size(0)\n",
    "                correct += pred.eq(label_indices).to(device).sum().item()\n",
    "                size += k\n",
    "\n",
    "            # Update max accuracy if current accuracy is higher\n",
    "        if correct > self.t_correct:\n",
    "            self.t_correct = correct\n",
    "\n",
    "        # Calculate and print accuracy\n",
    "        accuracy = 100. * correct / size\n",
    "        max_accuracy = 100. * self.t_correct / size\n",
    "        print('Accuracy : {}/{} ({:.2f}%) Max Accuracy : {}/{} ({:.2f}%) \\n'.\n",
    "              format(correct, size, accuracy, self.t_correct, size, max_accuracy))\n",
    "\n",
    "        # Save accuracy to a file\n",
    "        output_path = f'data/testresultsacc.txt'\n",
    "        with open(output_path, 'a') as output:\n",
    "            output.write(f'{accuracy}\\n')\n",
    "\n",
    "        print('Testing time:', time.time() - start)\n",
    "        return accuracy\n",
    "\n",
    "    def plot_loss(self):\n",
    "        \"\"\"\n",
    "        Visualizes training and validation loss over epochs.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(range(1, len(self.train_losses) + 1),\n",
    "                 self.train_losses, label=\"Train Loss\")\n",
    "        plt.plot(range(1, len(self.val_losses) + 1),\n",
    "                 self.val_losses, label=\"Validation Loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdada = CDADA(train_data, train_labels, test_data, test_labels,\n",
    "              num_classes=8, max_epoch=50, subset_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdada.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdada.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dataset(data, labels, title=\"Dataset Visualization\", classes=None, cmap='gray'):\n",
    "    \"\"\"\n",
    "    Visualizes the class distribution and random samples from the dataset.\n",
    "\n",
    "    Parameters:\n",
    "        data (np.ndarray): Wafer map images.\n",
    "        labels (np.ndarray): Corresponding labels (can be one-hot encoded).\n",
    "        title (str): Title for the visualization.\n",
    "        classes (list, optional): Class names corresponding to labels.\n",
    "        cmap (str): Colormap for grayscale images.\n",
    "    \"\"\"\n",
    "    # Convert one-hot labels to scalar indices if necessary\n",
    "    if len(labels.shape) > 1:  # Check if labels are one-hot encoded\n",
    "        labels = np.argmax(labels, axis=1)\n",
    "\n",
    "    # Plot class distribution\n",
    "    class_counts = Counter(labels)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(class_counts.keys(), class_counts.values())\n",
    "    plt.title(f\"Class Distribution: {title}\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    if classes:\n",
    "        plt.xticks(range(len(classes)), classes, rotation=45)\n",
    "    else:\n",
    "        plt.xticks(range(max(class_counts.keys()) + 1))\n",
    "    plt.show()\n",
    "\n",
    "    # Display random samples from the dataset\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
    "    indices = np.random.choice(len(data), size=5, replace=False)\n",
    "    for i, idx in enumerate(indices):\n",
    "        axes[i].imshow(data[idx].squeeze(), cmap=cmap)\n",
    "        axes[i].set_title(f\"Class: {labels[idx]}\")\n",
    "        axes[i].axis('off')\n",
    "    plt.suptitle(f\"Random Samples: {title}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset1 (WM811K)\n",
    "wm811k_data, wm811k_labels = preprocess_wm811k_data(\"data/WM811K.pkl\")\n",
    "\n",
    "# Class Names for WM811K\n",
    "wm811k_classes = ['Center', 'Donut', 'Edge-Loc', 'Edge-Ring',\n",
    "                  'Loc', 'Random', 'Scratch', 'Near-full', 'None']\n",
    "\n",
    "# Visualize WM811K Dataset\n",
    "visualize_dataset(wm811k_data, wm811k_labels,\n",
    "                  title=\"WM811K Dataset (Single Defect)\", classes=wm811k_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset2 (MixedWM38)\n",
    "mixed_data, mixed_labels = preprocess_npz_dataset(\"data/MLWM38K.npz\")\n",
    "\n",
    "# Class Names for MixedWM38\n",
    "mixed_classes = ['Center', 'Donut', 'Edge-Loc', 'Edge-Ring',\n",
    "                 'Loc', 'Random', 'Scratch', 'Near-full', 'None']\n",
    "\n",
    "# Visualize MixedWM38 Dataset\n",
    "visualize_dataset(mixed_data, mixed_labels,\n",
    "                  title=\"MixedWM38 Dataset (Single + Mixed Defects)\", classes=mixed_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ace-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
